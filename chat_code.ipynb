{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6917,"status":"ok","timestamp":1710029179494,"user":{"displayName":"Ahmed Sameh","userId":"11223303635463903245"},"user_tz":-120},"id":"GUddlv2y6awl","outputId":"d3091333-db95-404c-bd8e-f6f4bc172656"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1}],"source":["import numpy as np\n","import pickle as pk\n","import pandas as pd\n","import json\n","import re\n","from sklearn.preprocessing import LabelEncoder\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, LSTM, Dropout\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import WordNetLemmatizer\n","\n","nltk.download('punkt')\n","nltk.download('wordnet')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dNZczj5Z6h2Y"},"outputs":[],"source":["# Load the JSON data\n","with open('project_data.json') as file:\n","    data = json.load(file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ig1RY6NN6j3K"},"outputs":[],"source":["# Extract patterns, labels, and responses from the JSON data\n","training_patterns = []\n","training_labels = []\n","responses = {}\n","\n","for intent in data['intents']:\n","    patterns = intent['patterns']\n","    tag = intent['tag']\n","    response = intent['responses']\n","\n","    training_patterns.extend(patterns)\n","    training_labels.extend([tag] * len(patterns))\n","    responses[tag] = response"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sF0X9S9T6lax"},"outputs":[],"source":["# Clean and preprocess the text patterns using regular expressions and lemmatization\n","def clean_text(sentences):\n","    result = []\n","    lemmatizer = WordNetLemmatizer()\n","    for sentence in sentences:\n","        # Convert to lowercase\n","        sentence = sentence.lower()\n","        # Tokenize the sentence\n","        words = word_tokenize(sentence)\n","        # Lemmatize each word\n","        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n","        # Join the lemmatized words back into a sentence\n","        sentence = ' '.join(lemmatized_words)\n","        # Remove non-alphanumeric characters and extra whitespaces\n","        sentence = re.sub(r'[^a-zA-Z0-9\\s]', '', sentence)\n","        # Remove extra whitespaces\n","        sentence = re.sub(r'\\s+', ' ', sentence)\n","        result.append(sentence.strip())\n","    return result\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rk7YxhQL6lYh"},"outputs":[],"source":["# Clean the training patterns\n","training_patterns = clean_text(training_patterns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-FVbW5N6lWm"},"outputs":[],"source":["# Encode the training labels\n","label_encoder = LabelEncoder()\n","training_labels = label_encoder.fit_transform(training_labels)\n","training_labels = to_categorical(training_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M4FtTML26lUU"},"outputs":[],"source":["# Tokenize the training patterns\n","tokenizer = Tokenizer(num_words=500, oov_token='<OOV>')\n","tokenizer.fit_on_texts(training_patterns)\n","sequences = tokenizer.texts_to_sequences(training_patterns)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pYsKOt7s6lQN"},"outputs":[],"source":["# Pad sequences to ensure uniform length\n","max_sequence_length = 32\n","padded_sequences = pad_sequences(sequences, truncating='post', maxlen=max_sequence_length)"]},{"cell_type":"code","source":["len(tokenizer.word_index)+1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLvR_0PBmjzs","executionInfo":{"status":"ok","timestamp":1710029183644,"user_tz":-120,"elapsed":25,"user":{"displayName":"Ahmed Sameh","userId":"11223303635463903245"}},"outputId":"65463edb-6819-4a43-dc6e-fa03896b597e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["432"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":843,"status":"ok","timestamp":1710029184475,"user":{"displayName":"Ahmed Sameh","userId":"11223303635463903245"},"user_tz":-120},"id":"Ip9Ja89i6lOC","outputId":"7673859e-c8ca-4e49-b1cd-39d0db365315"},"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, None, 32)          13824     \n","                                                                 \n"," lstm (LSTM)                 (None, 128)               82432     \n","                                                                 \n"," dense (Dense)               (None, 256)               33024     \n","                                                                 \n"," dropout (Dropout)           (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 127)               32639     \n","                                                                 \n","=================================================================\n","Total params: 161919 (632.50 KB)\n","Trainable params: 161919 (632.50 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["# Define and compile the model with LSTM layer\n","model = Sequential()\n","model.add(Embedding(input_dim=432, output_dim=32))\n","model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n","model.add(Dense(256, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","model.summary()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWsJJL7t6lKt","executionInfo":{"status":"ok","timestamp":1710029817889,"user_tz":-120,"elapsed":633422,"user":{"displayName":"Ahmed Sameh","userId":"11223303635463903245"}},"outputId":"f2cb7350-f671-4e48-92ef-3b8d7f868cea"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","214/214 [==============================] - 18s 59ms/step - loss: 4.7472 - accuracy: 0.0112\n","Epoch 2/50\n","214/214 [==============================] - 12s 57ms/step - loss: 4.3125 - accuracy: 0.0328\n","Epoch 3/50\n","214/214 [==============================] - 12s 58ms/step - loss: 3.9890 - accuracy: 0.0609\n","Epoch 4/50\n","214/214 [==============================] - 12s 57ms/step - loss: 3.6921 - accuracy: 0.0937\n","Epoch 5/50\n","214/214 [==============================] - 12s 58ms/step - loss: 3.2288 - accuracy: 0.1621\n","Epoch 6/50\n","214/214 [==============================] - 14s 65ms/step - loss: 2.6875 - accuracy: 0.2793\n","Epoch 7/50\n","214/214 [==============================] - 13s 59ms/step - loss: 2.2018 - accuracy: 0.3955\n","Epoch 8/50\n","214/214 [==============================] - 13s 61ms/step - loss: 1.8825 - accuracy: 0.4789\n","Epoch 9/50\n","214/214 [==============================] - 13s 62ms/step - loss: 1.6183 - accuracy: 0.5408\n","Epoch 10/50\n","214/214 [==============================] - 12s 58ms/step - loss: 1.3658 - accuracy: 0.6045\n","Epoch 11/50\n","214/214 [==============================] - 12s 58ms/step - loss: 1.1065 - accuracy: 0.6626\n","Epoch 12/50\n","214/214 [==============================] - 12s 58ms/step - loss: 1.0099 - accuracy: 0.6992\n","Epoch 13/50\n","214/214 [==============================] - 13s 63ms/step - loss: 0.9023 - accuracy: 0.7151\n","Epoch 14/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.8100 - accuracy: 0.7385\n","Epoch 15/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.6348 - accuracy: 0.7976\n","Epoch 16/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.5710 - accuracy: 0.8182\n","Epoch 17/50\n","214/214 [==============================] - 13s 58ms/step - loss: 0.5402 - accuracy: 0.8360\n","Epoch 18/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.4695 - accuracy: 0.8566\n","Epoch 19/50\n","214/214 [==============================] - 12s 57ms/step - loss: 0.4415 - accuracy: 0.8604\n","Epoch 20/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.3729 - accuracy: 0.8744\n","Epoch 21/50\n","214/214 [==============================] - 14s 64ms/step - loss: 0.3805 - accuracy: 0.8838\n","Epoch 22/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.3699 - accuracy: 0.8791\n","Epoch 23/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.3347 - accuracy: 0.8950\n","Epoch 24/50\n","214/214 [==============================] - 13s 59ms/step - loss: 0.2977 - accuracy: 0.8941\n","Epoch 25/50\n","214/214 [==============================] - 13s 59ms/step - loss: 0.2941 - accuracy: 0.9053\n","Epoch 26/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.2448 - accuracy: 0.9241\n","Epoch 27/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.2758 - accuracy: 0.8932\n","Epoch 28/50\n","214/214 [==============================] - 13s 62ms/step - loss: 0.2572 - accuracy: 0.9157\n","Epoch 29/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.2841 - accuracy: 0.9072\n","Epoch 30/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.2168 - accuracy: 0.9203\n","Epoch 31/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.2195 - accuracy: 0.9213\n","Epoch 32/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.2058 - accuracy: 0.9316\n","Epoch 33/50\n","214/214 [==============================] - 12s 57ms/step - loss: 0.1840 - accuracy: 0.9306\n","Epoch 34/50\n","214/214 [==============================] - 12s 57ms/step - loss: 0.2119 - accuracy: 0.9213\n","Epoch 35/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1960 - accuracy: 0.9344\n","Epoch 36/50\n","214/214 [==============================] - 13s 63ms/step - loss: 0.2151 - accuracy: 0.9222\n","Epoch 37/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.2185 - accuracy: 0.9222\n","Epoch 38/50\n","214/214 [==============================] - 12s 57ms/step - loss: 0.1752 - accuracy: 0.9306\n","Epoch 39/50\n","214/214 [==============================] - 12s 57ms/step - loss: 0.1465 - accuracy: 0.9419\n","Epoch 40/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1908 - accuracy: 0.9381\n","Epoch 41/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1765 - accuracy: 0.9297\n","Epoch 42/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1649 - accuracy: 0.9400\n","Epoch 43/50\n","214/214 [==============================] - 13s 63ms/step - loss: 0.1685 - accuracy: 0.9410\n","Epoch 44/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1438 - accuracy: 0.9513\n","Epoch 45/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1656 - accuracy: 0.9381\n","Epoch 46/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1343 - accuracy: 0.9522\n","Epoch 47/50\n","214/214 [==============================] - 12s 57ms/step - loss: 0.1584 - accuracy: 0.9353\n","Epoch 48/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1492 - accuracy: 0.9456\n","Epoch 49/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1278 - accuracy: 0.9456\n","Epoch 50/50\n","214/214 [==============================] - 12s 58ms/step - loss: 0.1350 - accuracy: 0.9466\n"]}],"source":["# Train the model\n","history = model.fit(np.array(padded_sequences), training_labels, epochs=50, batch_size=5, verbose=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0TSqOXHP6lIK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710029818277,"user_tz":-120,"elapsed":400,"user":{"displayName":"Ahmed Sameh","userId":"11223303635463903245"}},"outputId":"c47b15b1-567f-4f34-9c1a-8348e05b8af9"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["model.save('model.h5') # save model\n","from tensorflow.keras.models import load_model\n","model=load_model('model.h5') # load model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bAuGqX_h6lF1"},"outputs":[],"source":["# Function to preprocess input text using regular expressions and lemmatization\n","def preprocess_input(text):\n","    # Convert to lowercase\n","    text = text.lower()\n","    # Tokenize the sentence\n","    words = word_tokenize(text)\n","    # Lemmatize each word\n","    lemmatizer = WordNetLemmatizer()\n","    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n","    # Join the lemmatized words back into a sentence\n","    text = ' '.join(lemmatized_words)\n","    # Remove non-alphanumeric characters and extra whitespaces\n","    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n","    # Remove extra whitespaces\n","    text = re.sub(r'\\s+', ' ', text)\n","    return text.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KaGNyG9X6lDK"},"outputs":[],"source":["# Function to predict intent\n","def predict_intent(input_text):\n","    input_text = preprocess_input(input_text)\n","    input_sequence = pad_sequences(tokenizer.texts_to_sequences([input_text]), maxlen=max_sequence_length)\n","    result_index = np.argmax(model.predict(np.array(input_sequence), verbose=0))\n","    predicted_intent = label_encoder.classes_[result_index]\n","    return predicted_intent"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wt2mkJ_6k9_"},"outputs":[],"source":["# Function to get response\n","def get_response(predicted_intent):\n","    for intent in data['intents']:\n","        if intent['tag'] == predicted_intent:\n","            responses = intent['responses']\n","            if isinstance(responses, list):\n","                return np.random.choice(responses)\n","            else:\n","                return responses"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6e739meN6k7l"},"outputs":[],"source":["#save encoder\n","pk.dump(label_encoder,open(\"label_encoder.pkl\",\"wb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NFbT0U5_6k48"},"outputs":[],"source":["#save tokinizer\n","pk.dump(tokenizer,open(\"tokenizer.pkl\",\"wb\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"T0Mjw_pt6k3E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1710029915927,"user_tz":-120,"elapsed":97377,"user":{"displayName":"Ahmed Sameh","userId":"11223303635463903245"}},"outputId":"2d7c34f9-93b8-49fb-8334-4fdc8a6ffb4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["User: quit\n"]}],"source":["\n","# Function for user chat\n","def user_chat():\n","    while True:\n","        print(\"User: \", end=\"\")\n","        user_input = input()\n","\n","        if user_input.lower() == 'quit':\n","            break\n","\n","        predicted_intent = predict_intent(user_input)\n","        response = get_response(predicted_intent)\n","        print('ChatBot:', response)\n","\n","# Start chatting\n","user_chat()\n"]}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbRWgie9BQa2RWvMcOhUpI"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}